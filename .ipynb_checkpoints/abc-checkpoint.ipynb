{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borrowing heavily from https://casmls.github.io/general/2016/10/02/abc.html, instead of the variational objective we use a Stein Variational Gradient Descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind ABC is simply to replace an intractable likelihood with an estimate based on the distance between two datasets. Because time series have a natural ordering, given two data sets \n",
    "\n",
    "$$d_1,d_2,...,d_T$$\n",
    "$$d'_1,d'_2,...,d'_T$$\n",
    "\n",
    "We can easily compute the distance $K(\\vec{d},\\vec{d'})$ under a Gaussian kernel to get an estimate of the distance between the two datasets (unlike, say, an unordered dataset which would require a summary statistic since any permutation of the dataset would be valid) \n",
    "\n",
    "\n",
    "In order to evaluate the validity of such an approach we attempt to replicate some results found here:\n",
    "http://kingaa.github.io/short-course/measles/measles.html\n",
    "\n",
    "where the authors discover that particle based methods lead to poor estimate of $R_0$.\n",
    "\n",
    "\n",
    "We first load the data (originally purposed for R) into python.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/gcgibson/Stein-Variational-Gradient-Descent/python/dat.json\") as f:\n",
    "    dat = f.read()\n",
    "    \n",
    "    \n",
    "    dat = dat.split(\",\")\n",
    "    time = []\n",
    "    cases = []\n",
    "    count = 0\n",
    "    for elm in dat:\n",
    "        if count % 2 ==0:\n",
    "            time.append(elm.split(\":\")[1])\n",
    "        else:\n",
    "            cases.append(int(elm.split(\":\")[1].replace(\"}\",\"\").replace(']\"]\\n',\"\")))\n",
    "        count +=1\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(cases)\n",
    "plt.show()\n",
    "\n",
    "cases = cases[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seasonal SIR model taken from http://www.princeton.edu/~dobber/pub/Altizer_etal_EcolLtrs2006.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a first pass we choose to ignore the covariates and simply consider the SEIR model.\n",
    "\n",
    "We first define a code block that is able to simulate trajectories from the SEIR model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.integrate as spi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def diff_eqs(INP,t,beta0,beta1, gamma,mu):  \n",
    "    '''The main set of equations'''\n",
    "    Y=np.zeros((3))\n",
    "    V = INP   \n",
    "    beta=beta0*(1+beta1*np.sin(2*np.pi*t))\n",
    "    Y[0] = mu - beta*V[0]*V[1] - mu*V[0]\n",
    "    Y[1] = beta*V[0]*V[1] - mu*V[1] - gamma*V[1]\n",
    "    Y[2] = gamma * V[1] - mu * V[2]\n",
    "    return Y   # For odeint\n",
    "\n",
    "\n",
    "def simulator(beta,gamma):\n",
    "    beta0=beta\n",
    "    \n",
    "    beta1=0.1\n",
    "    \n",
    "    mu=.0001;\n",
    "    S0=.9;\n",
    "    I0=1e-4;\n",
    "    INPUT=np.array((S0,I0, 1-S0-I0))\n",
    "\n",
    "    ND=MaxTime= 100;\n",
    "    TS=1.0\n",
    "    t_start = 0.0; t_end = ND; t_inc = TS\n",
    "    t_range = np.arange(t_start, t_end+t_inc, t_inc)\n",
    "    RES = spi.odeint(diff_eqs,INPUT,t_range,args=(beta0,beta1, gamma,mu))\n",
    "    return RES[1:,1]\n",
    "\n",
    "\n",
    "plt.plot(simulator(1.4,1./13))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an ability to sample from a deterministic SIR model, we can now use this as a plugin estimate of the likelihood under ABC.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named elfi",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-02626431111f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0melfi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melfi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named elfi"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import elfi\n",
    "\n",
    "beta = elfi.Prior('uniform', 0, 4)\n",
    "gamma = elfi.Prior('uniform', 0, 4)\n",
    "\n",
    "sim = elfi.Simulator(simulator, beta, gamma, observed=cases)\n",
    "\n",
    "\n",
    "def autocov(x):\n",
    "    return x\n",
    "S1 = elfi.Summary(autocov, sim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "class SVGD():\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def svgd_kernel(self, theta, h = -1):\n",
    "        sq_dist = pdist(theta)\n",
    "        pairwise_dists = squareform(sq_dist)**2\n",
    "        if h < 0: # if h < 0, using median trick\n",
    "            h = np.median(pairwise_dists)  \n",
    "            h = np.sqrt(0.5 * h / np.log(theta.shape[0]+1))\n",
    "\n",
    "        # compute the rbf kernel\n",
    "        Kxy = np.exp( -pairwise_dists / h**2 / 2)\n",
    "\n",
    "        dxkxy = -np.matmul(Kxy, theta)\n",
    "        sumkxy = np.sum(Kxy, axis=1)\n",
    "        for i in range(theta.shape[1]):\n",
    "            dxkxy[:, i] = dxkxy[:,i] + np.multiply(theta[:,i],sumkxy)\n",
    "        dxkxy = dxkxy / (h**2)\n",
    "        return (Kxy, dxkxy)\n",
    "    \n",
    " \n",
    "    def update(self, x0, lnprob, n_iter = 1000, stepsize = 1e-3, bandwidth = -1, alpha = 0.9, debug = False):\n",
    "        # Check input\n",
    "        if x0 is None or lnprob is None:\n",
    "            raise ValueError('x0 or lnprob cannot be None!')\n",
    "        \n",
    "        theta = np.copy(x0) \n",
    "        \n",
    "        # adagrad with momentum\n",
    "        fudge_factor = 1e-6\n",
    "        historical_grad = 0\n",
    "        for iter in range(n_iter):\n",
    "            if debug and (iter+1) % 1000 == 0:\n",
    "                print 'iter ' + str(iter+1) \n",
    "            \n",
    "            lnpgrad = lnprob(theta)\n",
    "            # calculating the kernel matrix\n",
    "            kxy, dxkxy = self.svgd_kernel(theta, h = -1)  \n",
    "            grad_theta = (np.matmul(kxy, lnpgrad) + dxkxy) / x0.shape[0]  \n",
    "            \n",
    "            # adagrad \n",
    "            if iter == 0:\n",
    "                historical_grad = historical_grad + grad_theta ** 2\n",
    "            else:\n",
    "                historical_grad = alpha * historical_grad + (1 - alpha) * (grad_theta ** 2)\n",
    "            adj_grad = np.divide(grad_theta, fudge_factor+np.sqrt(historical_grad))\n",
    "            theta = theta + stepsize * adj_grad \n",
    "            \n",
    "        return theta\n",
    "    \n",
    "import numpy as np\n",
    "import numpy.matlib as nm\n",
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "# Total population, N.\n",
    "\n",
    "\n",
    "class MVN:\n",
    "    def __init__(self,dataset):\n",
    "        self.dataset = dataset\n",
    "    def dlnprob(self, theta):\n",
    "        return_mat = []\n",
    "        for t in theta:\n",
    "            #prior N(0,1)\n",
    "    \n",
    "            return_mat.append( -(np.mean(sim(t,len(self.dataset))-self.dataset)))\n",
    "            \n",
    "        \n",
    "        return return_mat\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    model = MVN(cases)\n",
    "    \n",
    "    x0 = np.random.normal(0,1, [10,2]);\n",
    "    theta = SVGD().update(x0, model.dlnprob, n_iter=1000, stepsize=0.01)\n",
    "    #print (theta)\n",
    "    #print \"ground truth: \", np.exp(2)\n",
    "    print \"svgd mean: \", np.mean(theta,axis=0)\n",
    "    print \"svgd var: \", np.var(theta,axis=0)\n",
    "    print \"R_0 hat: \" , np.mean(theta,axis=0)[0]/np.mean(theta,axis=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
